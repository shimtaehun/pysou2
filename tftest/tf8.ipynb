{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14c0752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179.96714153 173.61735699 181.47688538 190.23029856 172.65846625\n",
      " 172.65863043 190.79212816 182.67434729 170.30525614 180.42560044\n",
      " 170.36582307 170.34270246 177.41962272 155.86719755 157.75082167\n",
      " 169.37712471 164.8716888  178.14247333 165.91975924 160.87696299\n",
      " 189.65648769 172.742237   175.67528205 160.75251814 169.55617275\n",
      " 176.1092259  163.49006423 178.75698018 168.9936131  172.0830625 ]\n",
      "[67.96846601 75.79354081 71.96633364 72.87265435 69.97365094 59.75682305\n",
      " 79.59880768 63.07369248 57.57274905 72.28222648 67.94840905 65.09673313\n",
      " 68.61549449 52.60151981 48.03296522 59.96476625 58.1069883  74.98534246\n",
      " 62.86192292 48.79867331 79.37996123 63.99415449 64.58808743 60.58514414\n",
      " 68.84431854 72.93285872 55.24695734 68.58382425 64.95184633 70.33586939]\n",
      "Epoch 10 / 1000 - Loss:2.49368, w:-0.64665, b:-0.00000\n",
      "Epoch 20 / 1000 - Loss:2.40834, w:-0.61748, b:-0.00000\n",
      "Epoch 30 / 1000 - Loss:2.32636, w:-0.58889, b:-0.00000\n",
      "Epoch 40 / 1000 - Loss:2.24760, w:-0.56087, b:-0.00000\n",
      "Epoch 50 / 1000 - Loss:2.17192, w:-0.53340, b:-0.00000\n",
      "Epoch 60 / 1000 - Loss:2.09922, w:-0.50648, b:-0.00000\n",
      "Epoch 70 / 1000 - Loss:2.02937, w:-0.48009, b:-0.00000\n",
      "Epoch 80 / 1000 - Loss:1.96226, w:-0.45423, b:-0.00000\n",
      "Epoch 90 / 1000 - Loss:1.89779, w:-0.42887, b:-0.00000\n",
      "Epoch 100 / 1000 - Loss:1.83584, w:-0.40402, b:-0.00000\n",
      "Epoch 110 / 1000 - Loss:1.77633, w:-0.37966, b:-0.00000\n",
      "Epoch 120 / 1000 - Loss:1.71915, w:-0.35579, b:-0.00000\n",
      "Epoch 130 / 1000 - Loss:1.66422, w:-0.33239, b:-0.00000\n",
      "Epoch 140 / 1000 - Loss:1.61144, w:-0.30945, b:-0.00000\n",
      "Epoch 150 / 1000 - Loss:1.56074, w:-0.28696, b:-0.00000\n",
      "Epoch 160 / 1000 - Loss:1.51202, w:-0.26493, b:-0.00000\n",
      "Epoch 170 / 1000 - Loss:1.46522, w:-0.24333, b:-0.00000\n",
      "Epoch 180 / 1000 - Loss:1.42025, w:-0.22215, b:-0.00000\n",
      "Epoch 190 / 1000 - Loss:1.37705, w:-0.20140, b:0.00000\n",
      "Epoch 200 / 1000 - Loss:1.33555, w:-0.18106, b:0.00000\n",
      "Epoch 210 / 1000 - Loss:1.29567, w:-0.16112, b:0.00000\n",
      "Epoch 220 / 1000 - Loss:1.25736, w:-0.14157, b:0.00000\n",
      "Epoch 230 / 1000 - Loss:1.22055, w:-0.12242, b:0.00000\n",
      "Epoch 240 / 1000 - Loss:1.18519, w:-0.10364, b:0.00000\n",
      "Epoch 250 / 1000 - Loss:1.15121, w:-0.08524, b:0.00000\n",
      "Epoch 260 / 1000 - Loss:1.11857, w:-0.06720, b:0.00000\n",
      "Epoch 270 / 1000 - Loss:1.08721, w:-0.04952, b:0.00000\n",
      "Epoch 280 / 1000 - Loss:1.05708, w:-0.03218, b:0.00000\n",
      "Epoch 290 / 1000 - Loss:1.02813, w:-0.01520, b:0.00000\n",
      "Epoch 300 / 1000 - Loss:1.00032, w:0.00145, b:0.00000\n",
      "Epoch 310 / 1000 - Loss:0.97360, w:0.01778, b:0.00000\n",
      "Epoch 320 / 1000 - Loss:0.94793, w:0.03377, b:0.00000\n",
      "Epoch 330 / 1000 - Loss:0.92327, w:0.04945, b:0.00000\n",
      "Epoch 340 / 1000 - Loss:0.89957, w:0.06482, b:0.00000\n",
      "Epoch 350 / 1000 - Loss:0.87681, w:0.07989, b:0.00000\n",
      "Epoch 360 / 1000 - Loss:0.85494, w:0.09466, b:0.00000\n",
      "Epoch 370 / 1000 - Loss:0.83392, w:0.10913, b:0.00000\n",
      "Epoch 380 / 1000 - Loss:0.81374, w:0.12332, b:0.00000\n",
      "Epoch 390 / 1000 - Loss:0.79434, w:0.13722, b:0.00000\n",
      "Epoch 400 / 1000 - Loss:0.77570, w:0.15085, b:0.00000\n",
      "Epoch 410 / 1000 - Loss:0.75780, w:0.16421, b:0.00000\n",
      "Epoch 420 / 1000 - Loss:0.74060, w:0.17731, b:0.00000\n",
      "Epoch 430 / 1000 - Loss:0.72408, w:0.19014, b:0.00000\n",
      "Epoch 440 / 1000 - Loss:0.70820, w:0.20273, b:0.00000\n",
      "Epoch 450 / 1000 - Loss:0.69294, w:0.21506, b:0.00000\n",
      "Epoch 460 / 1000 - Loss:0.67829, w:0.22714, b:0.00000\n",
      "Epoch 470 / 1000 - Loss:0.66421, w:0.23899, b:0.00000\n",
      "Epoch 480 / 1000 - Loss:0.65068, w:0.25061, b:0.00000\n",
      "Epoch 490 / 1000 - Loss:0.63769, w:0.26199, b:0.00000\n",
      "Epoch 500 / 1000 - Loss:0.62520, w:0.27315, b:0.00000\n",
      "Epoch 510 / 1000 - Loss:0.61320, w:0.28408, b:0.00000\n",
      "Epoch 520 / 1000 - Loss:0.60168, w:0.29480, b:0.00000\n",
      "Epoch 530 / 1000 - Loss:0.59061, w:0.30531, b:0.00000\n",
      "Epoch 540 / 1000 - Loss:0.57997, w:0.31561, b:0.00000\n",
      "Epoch 550 / 1000 - Loss:0.56975, w:0.32570, b:0.00000\n",
      "Epoch 560 / 1000 - Loss:0.55993, w:0.33560, b:0.00000\n",
      "Epoch 570 / 1000 - Loss:0.55049, w:0.34529, b:0.00000\n",
      "Epoch 580 / 1000 - Loss:0.54143, w:0.35480, b:0.00000\n",
      "Epoch 590 / 1000 - Loss:0.53272, w:0.36412, b:0.00000\n",
      "Epoch 600 / 1000 - Loss:0.52435, w:0.37325, b:0.00000\n",
      "Epoch 610 / 1000 - Loss:0.51632, w:0.38220, b:0.00000\n",
      "Epoch 620 / 1000 - Loss:0.50859, w:0.39098, b:0.00000\n",
      "Epoch 630 / 1000 - Loss:0.50117, w:0.39958, b:0.00000\n",
      "Epoch 640 / 1000 - Loss:0.49404, w:0.40801, b:0.00000\n",
      "Epoch 650 / 1000 - Loss:0.48720, w:0.41627, b:0.00000\n",
      "Epoch 660 / 1000 - Loss:0.48062, w:0.42437, b:0.00000\n",
      "Epoch 670 / 1000 - Loss:0.47430, w:0.43231, b:0.00000\n",
      "Epoch 680 / 1000 - Loss:0.46822, w:0.44009, b:0.00000\n",
      "Epoch 690 / 1000 - Loss:0.46239, w:0.44772, b:0.00000\n",
      "Epoch 700 / 1000 - Loss:0.45678, w:0.45519, b:0.00000\n",
      "Epoch 710 / 1000 - Loss:0.45140, w:0.46252, b:0.00000\n",
      "Epoch 720 / 1000 - Loss:0.44622, w:0.46970, b:0.00000\n",
      "Epoch 730 / 1000 - Loss:0.44125, w:0.47674, b:0.00000\n",
      "Epoch 740 / 1000 - Loss:0.43647, w:0.48364, b:0.00000\n",
      "Epoch 750 / 1000 - Loss:0.43188, w:0.49041, b:0.00000\n",
      "Epoch 760 / 1000 - Loss:0.42748, w:0.49704, b:0.00000\n",
      "Epoch 770 / 1000 - Loss:0.42324, w:0.50354, b:0.00000\n",
      "Epoch 780 / 1000 - Loss:0.41917, w:0.50991, b:0.00000\n",
      "Epoch 790 / 1000 - Loss:0.41526, w:0.51615, b:0.00000\n",
      "Epoch 800 / 1000 - Loss:0.41150, w:0.52227, b:0.00000\n",
      "Epoch 810 / 1000 - Loss:0.40790, w:0.52827, b:0.00000\n",
      "Epoch 820 / 1000 - Loss:0.40443, w:0.53415, b:0.00000\n",
      "Epoch 830 / 1000 - Loss:0.40110, w:0.53991, b:0.00000\n",
      "Epoch 840 / 1000 - Loss:0.39790, w:0.54556, b:0.00000\n",
      "Epoch 850 / 1000 - Loss:0.39482, w:0.55109, b:0.00000\n",
      "Epoch 860 / 1000 - Loss:0.39187, w:0.55652, b:0.00000\n",
      "Epoch 870 / 1000 - Loss:0.38903, w:0.56184, b:0.00000\n",
      "Epoch 880 / 1000 - Loss:0.38630, w:0.56705, b:0.00000\n",
      "Epoch 890 / 1000 - Loss:0.38368, w:0.57216, b:0.00000\n",
      "Epoch 900 / 1000 - Loss:0.38117, w:0.57717, b:0.00000\n",
      "Epoch 910 / 1000 - Loss:0.37875, w:0.58208, b:0.00000\n",
      "Epoch 920 / 1000 - Loss:0.37643, w:0.58690, b:0.00000\n",
      "Epoch 930 / 1000 - Loss:0.37419, w:0.59161, b:0.00000\n",
      "Epoch 940 / 1000 - Loss:0.37205, w:0.59624, b:0.00000\n",
      "Epoch 950 / 1000 - Loss:0.36999, w:0.60077, b:0.00000\n",
      "Epoch 960 / 1000 - Loss:0.36801, w:0.60521, b:0.00000\n",
      "Epoch 970 / 1000 - Loss:0.36611, w:0.60957, b:0.00000\n",
      "Epoch 980 / 1000 - Loss:0.36428, w:0.61383, b:0.00000\n",
      "Epoch 990 / 1000 - Loss:0.36253, w:0.61802, b:0.00000\n",
      "Epoch 1000 / 1000 - Loss:0.36084, w:0.62212, b:0.00000\n",
      "y_pred:  [69.45679473 65.85973681 70.31204203 75.2707196  65.31653956 65.31663256\n",
      " 75.58898766 70.99038628 63.98348125 69.71650484 64.01779151 64.00469403\n",
      " 68.01366344 55.80453712 56.871582   63.45770868 60.90544666 68.4231475\n",
      " 61.49916288 58.64249427 74.94566433 65.36399443 67.02552056 58.57199813\n",
      " 63.55913672 67.27134326 60.12277702 68.77125644 63.24045509 64.99058195]\n",
      "학습 결과--------------\n",
      "추정된 w: {model.w:.4f}\n",
      "추정된 b: {model.b:.4f}\n",
      "키:179.97cm, 몸무게 실제:67.97kg, 예측:69.46kg\n",
      "키:173.62cm, 몸무게 실제:75.79kg, 예측:65.86kg\n",
      "키:181.48cm, 몸무게 실제:71.97kg, 예측:70.31kg\n",
      "키:190.23cm, 몸무게 실제:72.87kg, 예측:75.27kg\n",
      "키:172.66cm, 몸무게 실제:69.97kg, 예측:65.32kg\n",
      "키:172.66cm, 몸무게 실제:59.76kg, 예측:65.32kg\n",
      "키:190.79cm, 몸무게 실제:79.60kg, 예측:75.59kg\n",
      "키:182.67cm, 몸무게 실제:63.07kg, 예측:70.99kg\n",
      "키:170.31cm, 몸무게 실제:57.57kg, 예측:63.98kg\n",
      "키:180.43cm, 몸무게 실제:72.28kg, 예측:69.72kg\n",
      "키:170.37cm, 몸무게 실제:67.95kg, 예측:64.02kg\n",
      "키:170.34cm, 몸무게 실제:65.10kg, 예측:64.00kg\n",
      "키:177.42cm, 몸무게 실제:68.62kg, 예측:68.01kg\n",
      "키:155.87cm, 몸무게 실제:52.60kg, 예측:55.80kg\n",
      "키:157.75cm, 몸무게 실제:48.03kg, 예측:56.87kg\n",
      "키:169.38cm, 몸무게 실제:59.96kg, 예측:63.46kg\n",
      "키:164.87cm, 몸무게 실제:58.11kg, 예측:60.91kg\n",
      "키:178.14cm, 몸무게 실제:74.99kg, 예측:68.42kg\n",
      "키:165.92cm, 몸무게 실제:62.86kg, 예측:61.50kg\n",
      "키:160.88cm, 몸무게 실제:48.80kg, 예측:58.64kg\n",
      "키:189.66cm, 몸무게 실제:79.38kg, 예측:74.95kg\n",
      "키:172.74cm, 몸무게 실제:63.99kg, 예측:65.36kg\n",
      "키:175.68cm, 몸무게 실제:64.59kg, 예측:67.03kg\n",
      "키:160.75cm, 몸무게 실제:60.59kg, 예측:58.57kg\n",
      "키:169.56cm, 몸무게 실제:68.84kg, 예측:63.56kg\n",
      "키:176.11cm, 몸무게 실제:72.93kg, 예측:67.27kg\n",
      "키:163.49cm, 몸무게 실제:55.25kg, 예측:60.12kg\n",
      "키:178.76cm, 몸무게 실제:68.58kg, 예측:68.77kg\n",
      "키:168.99cm, 몸무게 실제:64.95kg, 예측:63.24kg\n",
      "키:172.08cm, 몸무게 실제:70.34kg, 예측:64.99kg\n",
      "MSE(평균제곱오차):23.41608\n",
      "R^2(결정계수):0.63933\n"
     ]
    }
   ],
   "source": [
    "# 선형회귀모델 추세식 계산\n",
    "import numpy as np\n",
    "\n",
    "class LinearRegressionTest:\n",
    "    def __init__(self, learning_rate, epochs):\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.learning_rate = learning_rate\n",
    "        self. epochs = epochs\n",
    "\n",
    "    def fit(self, x:np.ndarray, y:np.ndarray):\n",
    "        # 경사하강법(Gradient Descent)으로 w, b를 학습\n",
    "        # parameter 초기화\n",
    "        self.w = np.random.uniform(-2, 2)\n",
    "        self.b = np.random.uniform(-2, 2)\n",
    "\n",
    "        n = len(x)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            y_pred = self.w * x + self.b        # 예측값\n",
    "            loss = np.mean((y - y_pred) ** 2)   # 손실()\n",
    "\n",
    "            dw = (-2 / n) * np.sum(x * (y - y_pred))    # 경사 계산. 편미분\n",
    "            db = (-2 / n) * np.sum(y - y_pred)\n",
    "\n",
    "            self.w -= self.learning_rate * dw\n",
    "            self.b = self.learning_rate * db\n",
    "\n",
    "            # 학습 상태 출력\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'Epoch {epoch + 1} / {self.epochs} - Loss:{loss:.5f}, w:{self.w:.5f}, b:{self.b:.5f}')\n",
    "    def predict(self, x:np.ndarray):\n",
    "        return self.w * x + self.b\n",
    "\n",
    "def main():\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # feature\n",
    "    x_heights = np.random.normal(175, 10, 30)\n",
    "\n",
    "    true_w = 0.7\n",
    "    true_b = -55\n",
    "    noise = np.random.normal(0, 5, 30)\n",
    "    # label\n",
    "    y_weights = true_w * x_heights + true_b + noise\n",
    "    print(x_heights)\n",
    "    print(y_weights)\n",
    "\n",
    "    # scaling(표준화) 안해도 무관\n",
    "    x_mean = np.mean(x_heights)\n",
    "    x_std = np.std(x_heights)\n",
    "    \n",
    "    y_mean = np.mean(y_weights)\n",
    "    y_std = np.std(y_weights)\n",
    "\n",
    "    x_heights_scaled = (x_heights - x_mean) / x_std\n",
    "    y_weights_scaled = (y_weights - y_mean) / y_std\n",
    "\n",
    "    # 모델학습\n",
    "    model = LinearRegressionTest(learning_rate=0.001, epochs=1000)\n",
    "    model.fit(x_heights_scaled, y_weights_scaled)\n",
    "\n",
    "    # 예측\n",
    "    y_pred_scaled = model.predict(x_heights_scaled) # 예측할 데이터를 인자로 전달\n",
    "\n",
    "    # 예측 결과 역변환\n",
    "    y_pred = (y_pred_scaled * y_std) + y_mean\n",
    "    print(\"y_pred: \", y_pred)\n",
    "\n",
    "    # 모델 성능 (MSE, R^2) 계산\n",
    "    mse = np.mean((y_weights - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_weights - np.mean(y_weights)) ** 2)\n",
    "    ss_res = np.sum((y_weights - y_pred) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "    print('학습 결과--------------')\n",
    "    print('추정된 w: {model.w:.4f}')\n",
    "    print('추정된 b: {model.b:.4f}')\n",
    "\n",
    "    for i in range(len(x_heights)):\n",
    "        print(f\"키:{x_heights[i]:.2f}cm, 몸무게 실제:{y_weights[i]:.2f}kg, 예측:{y_pred[i]:.2f}kg\")\n",
    "    print(f'MSE(평균제곱오차):{mse:.5f}')\n",
    "    print(f'R^2(결정계수):{r2:.5f}')\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
