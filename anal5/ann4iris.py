from sklearn.linear_model import Perceptron
from sklearn.datasets import load_iris
import numpy as np
import matplotlib.pyplot as plt

iris = load_iris()
idx = np.in1d(iris.target, [0, 2])  # 1 차원 배열의 각 요소가 두 번째 배열에도 있는지 테스트
X = iris.data[idx, 0:2]
y = iris.target[idx]

model = Perceptron(max_iter=100, eta0=0.1, random_state=1).fit(X, y)
XX_min, XX_max = X[:, 0].min() - 1, X[:, 0].max() + 1
YY_min, YY_max = X[:, 1].min() - 1, X[:, 1].max() + 1
XX, YY = np.meshgrid(np.linspace(XX_min, XX_max, 1000), np.linspace(YY_min, YY_max, 1000))
ZZ = model.predict(np.c_[XX.ravel(), YY.ravel()]).reshape(XX.shape)


plt.contour(XX, YY, ZZ, colors='k')
plt.scatter(X[:, 0], X[:, 1], c=y, s=30, edgecolor='k', linewidth=1)
idx = [22, 36, 70, 80]

plt.scatter(X[idx, 0], X[idx, 1], c='r', s=100, alpha=0.5)

for i in idx:
    plt.annotate(i, xy=(X[i, 0], X[i, 1] + 0.1))

    

plt.grid(False)
plt.show()


# bar chart

plt.bar(range(len(idx)), model.decision_function(X[idx]))
plt.xticks(range(len(idx)), idx)
plt.gca().xaxis.grid(False)
plt.title("Discriminant Function")
plt.show()

